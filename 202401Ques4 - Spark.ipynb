{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8c053c1-aa26-414e-b4ff-ffd446eaec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the Python code using Spark DataFrames and PySpark-related functions to fulfil each of the\n",
    "# following requirements. Appendix A provides a list of PySpark-related functions and their descriptions\n",
    "# for your reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce2b136e-1155-4d20-8fa5-18b9b5e74b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/17 17:42:39 WARN Utils: Your hostname, PC18. resolves to a loopback address: 127.0.1.1; using 172.27.86.249 instead (on interface eth0)\n",
      "25/07/17 17:42:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/17 17:42:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/07/17 17:42:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.types import IntegerType \n",
    "spark=SparkSession.builder.appName(\"SparkApp\").getOrCreate() \n",
    "spark = SparkSession.builder.getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "113d2faf-5865-49ab-a2cd-a77bc81c726a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------------+\n",
      "|    Name|Test|Assignment|Presentation|\n",
      "+--------+----+----------+------------+\n",
      "|Student1|  39|        34|          10|\n",
      "|Student2|  37|        47|           9|\n",
      "|Student3|  30|        33|           9|\n",
      "|Student4|  37|        49|           6|\n",
      "|Student5|  37|        46|           7|\n",
      "|Student6|  35|        40|          10|\n",
      "+--------+----+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = \"Name STRING, Test INT, Assignment INT, Presentation INT\"\n",
    "df = spark.read.option(\"header\", \"true\").csv(\"data/marks.csv\", schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58237e11-e1a3-4301-93eb-4730ece4c728",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Test: integer (nullable = true)\n",
      " |-- Assignment: integer (nullable = true)\n",
      " |-- Presentation: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e59b07a-adca-4098-bb04-ed510479dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  a) Get the total number of rows in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "746c4560-2e8b-45d5-99d9-e727a05faf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"Marks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7dec4a6-6c30-4be7-add0-bba6fd88e84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|TOTAL_ROWS|\n",
      "+----------+\n",
      "|         6|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_rows = spark.sql(\"SELECT COUNT(*) AS TOTAL_ROWS FROM MARKS\")\n",
    "total_rows.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc144a3e-c18e-4f04-acc2-87df5ab16565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b)Display the name and assignment mark for the first 5 students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8445620-523d-4ac6-a1df-544be089c420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|    NAME|ASSIGNMENT|\n",
      "+--------+----------+\n",
      "|Student1|        34|\n",
      "|Student2|        47|\n",
      "|Student3|        33|\n",
      "|Student4|        49|\n",
      "|Student5|        46|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_student = spark.sql(\"SELECT NAME,ASSIGNMENT FROM MARKS LIMIT 5\")\n",
    "first_student.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb52d4c-8fbf-48be-9030-5cc4967fffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c)Find the count of each test mark present in the dataset. For example, the output below indicates\n",
    "#   that 11 students obtained 31 marks in their test, 10 students obtained 34 marks in their test, and\n",
    "#   so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbe0267d-3807-4f9e-a61c-a49e6e36cc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|TEST|COUNT|\n",
      "+----+-----+\n",
      "|  39|    1|\n",
      "|  37|    3|\n",
      "|  35|    1|\n",
      "|  30|    1|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_marks = spark.sql(\"SELECT TEST, COUNT(TEST) AS COUNT FROM MARKS GROUP BY TEST ORDER BY TEST DESC\")\n",
    "count_marks.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719a7d71-4ca8-4b54-b651-e446295656b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d)Filter the rows with assignment marks that are greater than or equal to 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbdce82-c2fb-4a82-97d8-edd33f1d6eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d7f6fb5-2c3c-4fd4-9c10-2dff71acda72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------------+\n",
      "|    Name|Test|Assignment|Presentation|\n",
      "+--------+----+----------+------------+\n",
      "|Student2|  37|        47|           9|\n",
      "|Student4|  37|        49|           6|\n",
      "|Student5|  37|        46|           7|\n",
      "|Student6|  35|        40|          10|\n",
      "+--------+----+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"Assignment\") >= 40).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de7b84-ed53-4a3b-9e30-53e375d221de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e) Display the records sorted in descending order of the presentation marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad9b4c2-a79b-45fc-9d81-404a0452fc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dba6617f-c898-466f-ab51-dc8113b78b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------------+\n",
      "|    Name|Test|Assignment|Presentation|\n",
      "+--------+----+----------+------------+\n",
      "|Student1|  39|        34|          10|\n",
      "|Student6|  35|        40|          10|\n",
      "|Student2|  37|        47|           9|\n",
      "|Student3|  30|        33|           9|\n",
      "|Student5|  37|        46|           7|\n",
      "|Student4|  37|        49|           6|\n",
      "+--------+----+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(col(\"Presentation\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe7500f-f1c8-4e20-a0e1-8c0665e8ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f) Define a PySpark user-defined function (UDF) that computes the total mark by summing the\n",
    "#    marks for the test, assignment and presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523e4199-ca22-4edc-bfd6-4bce9dfc54ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5cd5353-4720-404b-af98-8c8804d6e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total(test, assignment, presentation):\n",
    "    return test + assignment + presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8535fab-d84a-4a34-a376-4bde88a9e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_total_udf = udf(compute_total, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7c299-1bdb-43a2-bfe1-aa72c63488d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g)Add a new column to df named “Total” which contains the total marks for the students. Use the\n",
    "#   UDF from Question 4 f) to compute this total mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f9d0cde-3c22-4ed0-aa6d-7b4eb3924ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------------+-----+\n",
      "|    Name|Test|Assignment|Presentation|Total|\n",
      "+--------+----+----------+------------+-----+\n",
      "|Student1|  39|        34|          10|   83|\n",
      "|Student2|  37|        47|           9|   93|\n",
      "|Student3|  30|        33|           9|   72|\n",
      "|Student4|  37|        49|           6|   92|\n",
      "|Student5|  37|        46|           7|   90|\n",
      "|Student6|  35|        40|          10|   85|\n",
      "+--------+----+----------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"Total\", compute_total_udf(\"Test\", \"Assignment\", \"Presentation\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58aa986b-5e7d-4271-aa9f-05d0450e0ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------------+-----+\n",
      "|    Name|Test|Assignment|Presentation|Total|\n",
      "+--------+----+----------+------------+-----+\n",
      "|Student1|  39|        34|          10|   83|\n",
      "|Student2|  37|        47|           9|   93|\n",
      "|Student3|  30|        33|           9|   72|\n",
      "|Student4|  37|        49|           6|   92|\n",
      "|Student5|  37|        46|           7|   90|\n",
      "|Student6|  35|        40|          10|   85|\n",
      "+--------+----+----------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-venv",
   "language": "python",
   "name": "de-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
